% This file was created with JabRef 2.10.
% Encoding: MacRoman


@Conference{sertanTonic,
  Title                    = {Score Informed Tonic Identification for Makam Music of Turkey},
  Author                   = {Sertan {\c S}ent{\"u}rk and Sankalp Gulati and Serra, Xavier},
  Booktitle                = {Proceedings of 14th International Society for Music Information Retrieval Conference},
  Year                     = {2013},

  Address                  = {Curitiba, Brazil},
  Pages                    = {175-180},

  Abstract                 = {Tonic is a fundamental concept in many music traditions and its automatic identification should be relevant for establishing the reference pitch when we analyse the melodic content of the music. In this paper, we present two methodologies for the identification of the tonic in audio recordings of makam music of Turkey, both taking advantage of some score information. First, we compute a prominent pitch and a audio kernel-density pitch class distribution (KPCD) from the audio recording. The peaks in the KPCD are selected as tonic candidates. The first method computes a score KPCD from the monophonic melody extracted from the score. Then, the audio KPCD is circular-shifted with respect to each tonic candidate and compared with the score KPCD. The best matching shift indicates the estimated tonic. The second method extracts the mono- phonic melody of the most repetitive section of the score. Normalising the audio prominent pitch with respect to each tonic candidate, the method attempts to link the repetitive structural element given in the score with the respective time-intervals in the audio recording. The result producing the most confident links marks the estimated tonic. We have tested the methods on a dataset of makam music of Turkey, achieving a very high accuracy (94.9\%) with the first method, and almost perfect identification (99.6\%) with the second method. We conclude that score informed tonic identification can be a useful first step in the computational analysis (e.g. expressive analysis, intonation analysis, audio-score alignment) of music collections involving melody-dominant content.},
  ISBN                     = {978-0-615-90065-0}
}

@Article{senturk2877,
  Title                    = {Linking Scores and Audio Recordings in Makam Music of Turkey},
  Author                   = {Sertan {\c S}ent{\"u}rk and Andr{\'e} Holzapfel and Serra, Xavier},
  Journal                  = {Journal of New Music Research},
  Year                     = {2014},

  Month                    = {03/2014},
  Pages                    = {34-52},
  Volume                   = {43},

  Abstract                 = {The most relevant representations of music are notations and audio recordings, each of which emphasizes a particular perspective and promotes different approximations in the analysis and understanding of music. Linking these two representations and analyzing them jointly should help to better study many musical facets by being able to combine complementary analysis methodologies. In order to develop accurate linking methods, we have to take into account the specificities of a given type of music. In this paper, we present a method for linking musically relevant sections in a score of a piece from makam music of Turkey (MMT) to the corresponding time intervals of an audio recording of the same piece. The method starts by extracting relevant features from the score and from the audio recording. The features of a given score section are compared with the features of the audio recording to find the candidate links in the audio for that score section. Next, using the sequential section information stored in the score, it selects the most likely links. The method is tested on a dataset consisting of instrumental and vocal compositions of MMT, achieving 92.1\% and 96.9\% F1-scores on the instrumental and vocal pieces, respectively. Our results show the importance of culture-specific and knowledge-based approaches in music information processing.}
}

@InProceedings{durrieu2009main,
  Title                    = {Main instrument separation from stereophonic audio signals using a source/filter model},
  Author                   = {Durrieu, Jean-Louis and Ozerov, Alexey and F{\'e}votte, C{\'e}dric and Richard, Ga{\"e}l and David, Bertrand},
  Booktitle                = {European Signal Processing Conference (EUSIPCO), Glasgow, Scotland},
  Year                     = {2009},

  Review                   = {Presents an approach for Parametrization of spectrum as sum of predominant voiice and accompaniment instruments.

Spectrum and melodic and timbral components}
}

@Book{ederer2011theory,
  Title                    = {The Theory and Praxis of Makam in Classical Turkish Music 1910--2010},
  Author                   = {Ederer, Eric Bernard},
  Publisher                = {University of California, Santa Barbara},
  Year                     = {2011}
}

@Article{FilipsThesis,
  Title                    = {MAsters Thesis},
  Author                   = {Filip},

  Review                   = {The phonetic features are : 
a vector of the 9 log-probabilities of the 9 vocals in the vocal trapezoid
for a given vocal a model with these 9 probabilitiesis trained using the vocal joystick voiwe corpus.

It has been proposed a HMM that has 2 dimensions - horizaontal note states dimension
and 
vertical - phoneme state duration
HOWEVER! this model is not applied but a simple mmoel : 
The vowel information is incorporated in the output distributions using only a single stationary manifestation per note

------------------
the vowel and the pitch features are mutually independent. ... This justifies the fact that we can consider them as two independent sets of features

According to the method found in Rap99 the output probability of a combined feature vector can be represented as the product of output probability of the two independent feature sets. 
Since a feature set is driven by an indep. Gaussian, we can combine them straightforward into a common Gaussian.},
  Timestamp                = {2013.05.07}
}

@InProceedings{karaosmanouglu2012turkish,
  Title                    = {A {T}urkish makam music symbolic database for music information retrieval: SymbTr},
  Author                   = {Karaosmano{\u{g}}lu, M Kemal},
  Booktitle                = {Proceedings of the 13th International Society for Music Information Retrieval Conference},
  Year                     = {2012},

  Address                  = {Porto, Portugal}
}

@InProceedings{karaosmanouglu2014symbolic,
  Title                    = {A Symbolic Dataset of {T}urkish Makam Music Phrases},
  Author                   = {Karaosmano{\u{g}}lu, M. Kemal and Bozkurt, Bar{\i}{\c{s}} and Holzapfel, Andre and Do{\u{g}}rus{\"o}z Di{\c{s}}ia{\c{c}}{\i}k, Nilg{\"u}n},
  Booktitle                = {Fourth International Workshop on Folk Music Analysis (FMA2014)},
  Year                     = {2014}
}

@Article{rao2010vocal,
  Title                    = {Vocal melody extraction in the presence of pitched accompaniment in polyphonic music},
  Author                   = {Rao, Vishweshwara and Rao, Preeti},
  Journal                  = {Audio, Speech, and Language Processing, IEEE Transactions on},
  Year                     = {2010},
  Number                   = {8},
  Pages                    = {2145--2154},
  Volume                   = {18},

  Publisher                = {IEEE}
}

@Article{Salor2007580,
  Title                    = {{T}urkish speech corpora and recognition tools developed by porting SONIC: Towards multilingual speech recognition },
  Author                   = {{\"O}zg{\"u}l Salor and Bryan L. Pellom and Tolga Ciloglu and Mübeccel Demirekler},
  Journal                  = {Computer Speech and Language },
  Year                     = {2007},
  Number                   = {4},
  Pages                    = {580 - 593},
  Volume                   = {21},

  Doi                      = {http://dx.doi.org/10.1016/j.csl.2007.01.001},
  ISSN                     = {0885-2308},
  Keywords                 = {Phonetic aligner},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0885230807000022}
}

@InProceedings{senturk2012approach,
  Title                    = {An Approach for Linking Score and Audio Recordings in Makam Music of {T}urkey},
  Author                   = {Sentuerk and Sent{\"u}rk, Sertan and Holzapfel, Andr{\'e} and Serra, Xavier},
  Booktitle                = {Serra X, Rao P, Murthy H, Bozkurt B, editors. Proceedings of the 2nd CompMusic Workshop; 2012 Jul 12-13; Istanbul, Turkey. Barcelona: Universitat Pompeu Fabra; 2012. p. 95-106.},
  Year                     = {2012},
  Organization             = {Universitat Pompeu Fabra},

  Review                   = {different tunings and extensive usage of non-notated expressive elements.
 Addresses the peculiarities in the musical properties of makams in conrast to western music
e.g. : non-notated expressive elements (e.g. embelishments), change in tuning

Starting and ending of sections are provided from the musical score.

A synthetic pitch contour is synthesized from the notes, to which marks for the section boundaries are linked.
Then the synthetic pitch contour is matched to a f0-contour extracted from the audio signal. The result of the matching are time locations in the audio, which correspond to the section boundaries.

Methodology in detail: 
From the audio recording, the fundamental frequency, f0,
is estimated and processed to obtain an audio pitch contour. The f0 estimation is also used to calculate a pitch
histogram in order to identify the tuning and the note intervals (Section 3.2.1). From the score information, we read
the note symbols, the sections and the makam of the piece,
and generate a synthetic pitch contour (Section 3.2.2). In
order to estimate the candidate locations of the sections in
the audio, the method compares these relevant pitch representations (Section 3.3). In the Þnal step, the candidates
are hierarchically checked to link the sections of the score
to the corresponding parts in the audio (Section 3.4).}
}

@Conference{CompMusic2276,
  Title                    = {A Multicultural Approach in Music Information Research},
  Author                   = {Serra, Xavier},
  Booktitle                = {Int. Soc. for Music Information Retrieval Conf. (ISMIR)},
  Year                     = {2011},

  Address                  = {Miami, Florida (USA)},
  Month                    = {24/10/11},
  Pages                    = {151-156},

  Abstract                 = {<p>Our information technologies do not respond to the world\&$\#$39;s multicultural reality; in fact, we are imposing the paradigms of our market-driven western culture also on IT, thus facilitating the access of a small part of the world\&rsquo;s information to a small part of the world\&$\#$39;s population. The current IT research efforts may even make it worse, and future IT will accentuate this information bias. Most IT research is being carried out with a western centered approach and as a result, most of our data models, cognition models, user models, interaction models, ontologies, etc., are culturally biased. This fact is quite evident in music information re-search, since, despite the world\&$\#$39;s richness in terms of musi-cal culture, most research is centered on CDs and metadata of western commercial music. This is the motivation behind a large and ambitious project funded by the European Research Council entitled \&quot;CompMusic: Computational Models for the discovery of the world\&$\#$39;s music.\&quot; In this paper we present the ideas supporting this project, the challenges that we want to work on, and the proposed approaches to tackle these challenges.</p>},
  Keywords                 = {CompMusic, Multiculturalism},
  Url                      = {system/files/publications/Serra-Xavier-CompMusic-ISMIR-2011.pdf}
}

@InProceedings{sordo2012musically,
  Title                    = {A Musically aware system for browsing and interacting with audio music collections},
  Author                   = {Sordo, Mohamed and Koduri, Gopala Krishna and Sent{\"u}rk, Sertan and Gulati, Sankalp and Serra, Xavier},
  Booktitle                = {Serra X, Rao P, Murthy H, Bozkurt B, editors. Proceedings of the 2nd CompMusic Workshop; 2012 Jul 12-13; Istanbul, Turkey. Barcelona: Universitat Pompeu Fabra; 2012.},
  Year                     = {2012},
  Organization             = {Universitat Pompeu Fabra},

  Review                   = {distance measures are needed to navigate through the different information objects. 
It is desired that the system is able to explore all the musical elements of a collection of music. An example is searching by a musical phrase, rhythmic pattern or an expressive articulation of vocals. The latter is a musical aspect that is dependent on the lyrics to the song. To enable a comparison between a query of a certain articulation of vocals and a set of target articulations, a musically-aware similarity metric has to be defined.

--- 
features extracted so far.}
}

@InProceedings{uyar2014corpus_dlfm,
  Title                    = {{A corpus for computational research of Turkish makam music}},
  Author                   = {Uyar, Burak and Atl{{\i}}, Hasan Sercan and {\c{S}}ent{\"{u}}rk, Sertan and Bozkurt, Bar{{\i}}{\c{s}} and Serra, Xavier},
  Booktitle                = {1st International Digital Libraries for Musicology Workshop},
  Year                     = {2014},

  Address                  = {London, United Kingdom},
  Pages                    = {57--63},

  Abstract                 = {Each music tradition has its own characteristics in terms of melodic, rhythmic and timbral properties as well as semantic understandings. To analyse, discover and explore these culture-specific characteristics, we need music collections which are representative of the studied aspects of the music tradition. For Turkish makam music, there are various resources available such as audio recordings, music scores, lyrics and editorial metadata. However, most of these resources are not typically suited for computational analysis, are hard to access, do not have sufficient quality or do not include adequate descriptive information. In this paper we present a corpus of Turkish makam music created within the scope of the CompMusic project. The corpus is intended for computational research and the primary considerations during the creation of the corpus reflect some criteria, namely, purpose, coverage, completeness, quality and re-usability. So far, we have gathered approximately 6000 audio recordings, 2200 music scores with lyrics and 27000 instances of editorial metadata related to Turkish makam music. The metadata include information about makams, recordings, scores, compositions, artists etc. as well as the interrelations between them. In this paper, we also present several test datasets of Turkish makam music. Test datasets contain manual annotations by experts and they provide ground truth for specific computational tasks to test, calibrate and improve the research tools. We hope that this research corpus and the test datasets will facilitate academic studies in several fields such as music information retrieval and computational musicology.},
  Doi                      = {10.1145/2660168.2660174},
  ISBN                     = {9781450330022},
  Url                      = {http://sertansenturk.com/uploads/publications/uyar2014corpus\_dlfm.pdf}
}

@Article{anonyGeorgi,
  Title                    = {suppressed for anonymity},

  Review                   = {step 1: pitch salience : frame-by-frame based
step 2: contour creation : based on time continuity (duration from note to short phrases). 
temporal creation auditory streaming/snake : It is based on the snake principles - add peak from next frame 
step 3: select melody : iterate n times. based on continuity of the contour, vibrato


http://www.justinsalamon.com/melody-extraction.html}
}

@Article{anonymity,
  Title                    = {suppressed for anonymity}
}

@Article{Justin,
  Title                    = {Melody Extraction from Polyphonic Music Signals using Pitch Contour Characteristics},
  Journal                  = {IEEE Transactions on Audio, Speech and Language Processing},
  Year                     = {2012},

  Month                    = {08/2012},
  Pages                    = {1759-1770},
  Volume                   = {20},

  Review                   = {step 1: pitch salience : frame-by-frame based
step 2: contour creation : based on time continuity (duration from note to short phrases). 
temporal creation auditory streaming/snake : It is based on the snake principles - add peak from next frame 
step 3: select melody : iterate n times. based on continuity of the contour, vibrato


http://www.justinsalamon.com/melody-extraction.html}
}

